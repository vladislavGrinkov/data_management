{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "genetic-madness",
   "metadata": {},
   "source": [
    "### Домашняя работа\n",
    "\n",
    "Группа: Т12О-101М-20\n",
    "\n",
    "Студент: Гриньков Владислав Леонидович\n",
    "\n",
    "Тема: Реализация наивного байесовского классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "insured-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import Generic, TypeVar, List, Dict, Any\n",
    "\n",
    "\n",
    "InputType = TypeVar('InputType', bound=list)\n",
    "OutputType = TypeVar('OutputType')\n",
    "\n",
    "\n",
    "class NaiveBayesClassifier(Generic[InputType, OutputType]):\n",
    "    \"\"\"\n",
    "    P(class|data) = (P(data|class) * P(class)) / P(data)\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        self.count_of_unique_targets: Dict[OutputType, int] = {}\n",
    "        self.aprior_probability_of_target: Dict[OutputType, float] = {}\n",
    "\n",
    "        self.unique_input_column_counts: Dict[Any, int] = {}\n",
    "        self.input_column_counts_by_target: Dict[OutputType, Dict[Any, int]] = {}\n",
    "        self.input_column_probabilities_by_target: Dict[OutputType, Dict[Any, float]] = {}\n",
    "\n",
    "    def fit(self, inputs: List[InputType], targets: List[OutputType]):\n",
    "        if len(inputs) != len(targets):\n",
    "            raise ValueError('length of inputs and targets mismatched')\n",
    "\n",
    "        # Count probabilities of targets\n",
    "        count_of_unique_targets = Counter(targets)\n",
    "        self.count_of_unique_targets.update(count_of_unique_targets)\n",
    "\n",
    "        all_items_count = sum(self.count_of_unique_targets.values())\n",
    "        self.aprior_probability_of_target = {\n",
    "            target: target_items_count / all_items_count\n",
    "            for target, target_items_count in self.count_of_unique_targets.items()\n",
    "        }\n",
    "\n",
    "        # Count frequencies of inputs\n",
    "        for target, input in zip(targets, inputs):\n",
    "            self.input_column_counts_by_target.setdefault(target, {})\n",
    "\n",
    "            for item, count in Counter(input).items():\n",
    "                self.unique_input_column_counts.setdefault(item, 0)\n",
    "                self.input_column_counts_by_target[target].setdefault(item, 0)\n",
    "\n",
    "                self.unique_input_column_counts[item] += 1\n",
    "                self.input_column_counts_by_target[target][item] += count\n",
    "\n",
    "        all_column_values_count = sum(self.unique_input_column_counts.values())\n",
    "        self.input_column_probabilities_by_target = {\n",
    "            target: {\n",
    "                input_item: count / all_column_values_count\n",
    "                for input_item, count in input_counts.items()\n",
    "            }\n",
    "            for target, input_counts in self.input_column_counts_by_target.items()\n",
    "        }\n",
    "\n",
    "    def predict(self, input: InputType) -> Dict[OutputType, float]:\n",
    "        aposterior_target_probas: Dict[OutputType, float] = dict.fromkeys(self.count_of_unique_targets.keys(), 1.0)\n",
    "\n",
    "        for item in input:\n",
    "            for target in aposterior_target_probas:\n",
    "                aposterior_target_probas[target] *= self.input_column_probabilities_by_target[target].get(item, 0)\n",
    "\n",
    "        return aposterior_target_probas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-diesel",
   "metadata": {},
   "source": [
    "### Тестируем классфикатор"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-individual",
   "metadata": {},
   "source": [
    "Будем использовать датасет с spam смс'ками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "individual-messaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sms_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                           sms_text\n",
       "0  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "1   ham  U dun say so early hor... U c already then say...\n",
       "2   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = 'data/sms_spam_collection.tar.gz'\n",
    "\n",
    "df = pd.read_csv(\n",
    "    filename,\n",
    "    compression='gzip',\n",
    "    header=1,\n",
    "    sep='\\t',\n",
    "    encoding='utf8',\n",
    "    names=['class', 'sms_text'],\n",
    "    error_bad_lines=False\n",
    ")\n",
    "\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-engineer",
   "metadata": {},
   "source": [
    "Посмотрим на его размерность (2 колонки и 5571 строчка)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "entire-stream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5571, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-serial",
   "metadata": {},
   "source": [
    "Выкинем все NaN значения чтобы не путать классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "congressional-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-glucose",
   "metadata": {},
   "source": [
    "Сделаем функции для преобразования текста в вектор слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "excited-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def text_preprocess(sms_text: str) -> str:\n",
    "    \"\"\"Преобразование текста для анализа\"\"\"\n",
    "    text_no_punctuation = ''.join([\n",
    "        char\n",
    "        for char in sms_text\n",
    "        if char not in string.punctuation\n",
    "    ])\n",
    "    text_lowercase = ' '.join([\n",
    "        word.lower()\n",
    "        for word in text_no_punctuation.split(sep=' ')\n",
    "    ])\n",
    "    \n",
    "    return text_lowercase\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    try:\n",
    "        processed_text = text_preprocess(text)\n",
    "        tokens = processed_text.split(' ')\n",
    "    except TypeError:\n",
    "        print(f'Ошибка при обработке текста sms: {text}')\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-louisiana",
   "metadata": {},
   "source": [
    "Подготовим данные на которых будет обучаться классификато"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "artificial-korean",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [tokenize_text(s) for s in df['sms_text'].tolist()]\n",
    "targets = df['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "twenty-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NaiveBayesClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-cabinet",
   "metadata": {},
   "source": [
    "Обучаем классфикатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "laden-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-money",
   "metadata": {},
   "source": [
    "А вот и тест на рандомной строчке из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "compact-spiritual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At index 4929: class=spam text='Hi, the SEXYCHAT girls are waiting for you to text them. Text now for a great night chatting. send STOP to stop this service'\n",
      "\n",
      "Predicted    : {'spam': 3.691409012291068e-77, 'ham': 0.0}\n",
      "Most probably: ('spam', 3.691409012291068e-77)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "idx = random.randint(0, df.shape[0])\n",
    "random_input = df['sms_text'].values[idx]\n",
    "random_target = df['class'].values[idx]\n",
    "\n",
    "print(f'At index {idx}: class={random_target} text={random_input!r}\\n')\n",
    "\n",
    "probas = clf.predict(tokenize_text(random_input))\n",
    "print('Predicted    :', probas)\n",
    "print('Most probably:', max(probas.items(), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-basement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
