{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашняя работа\n",
    "Группа: Т12О-101М-20\n",
    "\n",
    "Студент: Гриньков Владислав Леонидович\n",
    "\n",
    "### Задача 1: применяем PCA-трансформацию\n",
    "\n",
    "Модифицируйте файл train.py - добавьте в пайплайн обучения модели сжатие размерности до n_components=2 с помощью PCA и обучите модель в докере на \"сжатых\" данных. Сохраните полученный объект pca_transformer.pkl, который умеет выполнять сжатие данных.\n",
    "\n",
    "Решением домашки считается модифицированный файл train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-25 16:46:45,878 | INFO     | <ipython-input-7-625032a3:30   | T-SNE Transformer обучен и сохранен в /home/cdayz/Sources/university/data_management_homeworks/jupyter/pca_transformer.pkl\n",
      "2021-04-25 16:46:45,881 | INFO     | <ipython-input-7-625032a3:41   | Модель обучена и сохранена в /home/cdayz/Sources/university/data_management_homeworks/jupyter/clf.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- ВАШ КОД ТУТ --\n",
    "import pickle\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "LOG_FORMAT = '%(asctime)s | %(levelname)-8s | %(filename)-25.25s:%(lineno)-4d | %(message)s'\n",
    "\n",
    "# NOTE: отключил логирование в файл при запуске в jupyter\n",
    "# log_filename = \"/www/classifier/data/service.log\"\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\n",
    "\n",
    "def load_data(from_file: Path):\n",
    "    data_source = np.genfromtxt(from_file.resolve().as_posix(), delimiter=',', skip_header=1)\n",
    "    X = data_source[:, :3]\n",
    "    y = data_source[:, 3]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def transformer(X, save_into: Path):\n",
    "    pca_transformer = PCA(n_components=2).fit(X)\n",
    "    X_pca = pca_transformer.transform(X)\n",
    "    \n",
    "    with save_into.open('wb') as f:\n",
    "        pickle.dump(pca_transformer, f)\n",
    "        logging.info('T-SNE Transformer обучен и сохранен в %s' % save_into.resolve())\n",
    "        \n",
    "    return X_pca\n",
    "\n",
    "\n",
    "def classifier(X, y, save_into: Path): \n",
    "    clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    with open('clf.pkl', 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "        logging.info('Модель обучена и сохранена в %s' % save_into.resolve())\n",
    "\n",
    "\n",
    "def pipeline():\n",
    "    X, y = load_data(Path('data/client_segmentation.csv'))\n",
    "    X = transformer(X, save_into=Path('./pca_transformer.pkl'))\n",
    "\n",
    "    classifier(X, y, save_into=Path('./clf.pkl'))\n",
    "    \n",
    "\n",
    "pipeline()\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: трансформация входных фичей на лету\n",
    "\n",
    "Модифицируйте файл `service.py`: добавьте загрузку объекта для трансформации `pca_tansformer.pkl` и применяйте её **в докере** для трансформации набора входных фич в сжатые:\n",
    "<pre>\n",
    "[x1, x2, x3] -> [x1_pca, x2_pca]\n",
    "</pre>\n",
    "\n",
    "Соответственно, predict надо выполнять на *сжатых* фичах\n",
    "\n",
    "\n",
    "Решением домашки считается модифицированный файл *service.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-25 16:46:51,773 | INFO     | <ipython-input-8-e5306d3d:90   | Загружаем обученную модель\n",
      "2021-04-25 16:46:51,774 | INFO     | <ipython-input-8-e5306d3d:93   | Модель загружена: DecisionTreeClassifier(max_depth=3, random_state=42)\n",
      "2021-04-25 16:46:51,776 | INFO     | <ipython-input-8-e5306d3d:97   | Модель загружена: PCA(n_components=2)\n"
     ]
    }
   ],
   "source": [
    "# --- ВАШ КОД ТУТ --\n",
    "\"\"\"\n",
    "Умеет выполнять классификацию клиентов по трём фичам\n",
    "Запускаем из python3:\n",
    "    python3 service.py\n",
    "Проверяем работоспособность:\n",
    "    curl http://127.0.0.1:5000/\n",
    "\"\"\"\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import http.server\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import socketserver\n",
    "import sys\n",
    "from http import HTTPStatus\n",
    "from re import compile\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# файл, куда посыпятся логи модели\n",
    "\n",
    "LOG_FORMAT = '%(asctime)s | %(levelname)-8s | %(filename)-25.25s:%(lineno)-4d | %(message)s'\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\n",
    "\n",
    "\n",
    "def parse_params(params) -> dict:\n",
    "    \"\"\"\n",
    "        Выдираем параметры из GET-запроса\n",
    "    \"\"\"\n",
    "    params_list = params.split('&')\n",
    "    params_dict = {'x1': None, 'x2': None, 'x3': None}\n",
    "    for param in params_list:\n",
    "        key, value = param.split('=')\n",
    "        params_dict[key] = float(value)\n",
    "    return params_dict\n",
    "\n",
    "\n",
    "class Handler(http.server.SimpleHTTPRequestHandler):\n",
    "    \"\"\"Простой http-сервер\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        \n",
    "    def handle_ping(self) -> dict:\n",
    "        return {'message': 'pong'}\n",
    "\n",
    "    def handle_query(self, params: dict) -> dict:\n",
    "        response = params\n",
    "        used_features = self.reduce_features(params)\n",
    "        predicted_class = int(classifier_model.predict(used_features)[0])\n",
    "        \n",
    "        logging.info('predicted_class %s' % predicted_class)\n",
    "        response.update({'predicted_class': predicted_class})\n",
    "        \n",
    "        return response\n",
    "\n",
    "    def reduce_features(self, features: dict) -> dict:\n",
    "        return transformer.transform(np.array([[features['x1'], features['x2'], features['x3']]]))\n",
    "\n",
    "        \n",
    "    def get_response(self) -> dict:\n",
    "        \"\"\"Пример запроса\n",
    "        \n",
    "        http://0.0.0.0:5000/classifier/?x1=1&x2=-2.2&x3=1.05\n",
    "        \"\"\"\n",
    "        response = {'ping': 'ok'}\n",
    "        url_with_params = self.path.split('?')\n",
    "\n",
    "        if len(url_with_params) == 2 and self.path.startswith('/classifier'):\n",
    "            return self.handle_query(parse_params(url_with_params[1]))\n",
    "\n",
    "        elif self.path.startswith('/ping/'):\n",
    "            return self.handle_ping()\n",
    "\n",
    "        return response\n",
    "\n",
    "    def do_GET(self):\n",
    "        # заголовки ответа\n",
    "        self.send_response(HTTPStatus.OK)\n",
    "        self.send_header(\"Content-type\", \"application/json\")\n",
    "        self.end_headers()\n",
    "        self.wfile.write(json.dumps(self.get_response()).encode())\n",
    "\n",
    "\n",
    "logging.info('Загружаем обученную модель')\n",
    "with open('./clf.pkl', 'rb') as f:\n",
    "    classifier_model = pickle.load(f)\n",
    "    logging.info('Модель загружена: %s' % classifier_model)\n",
    "\n",
    "with open('./pca_transformer.pkl', 'rb') as f:\n",
    "    transformer = pickle.load(f)\n",
    "    logging.info('Модель загружена: %s' % transformer)\n",
    "\n",
    "\n",
    "# NOTE: disbale for not start server in jupyter\n",
    "# if __name__ == '__main__':\n",
    "#     logging.info('Server started')\n",
    "#     classifier_service = socketserver.TCPServer(('', 5000), Handler)\n",
    "#     classifier_service.serve_forever()\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: Используем Flask\n",
    "\n",
    "Перепишите сервис на использование Flask. Вы можете взять готовый базовый образ с Flask, либо добавить установку в тот контейнер, который есть - это нужно сделать в Dockerfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-25 16:49:26,168 | INFO     | <ipython-input-12-babc6e1:41   | Модель загружена: DecisionTreeClassifier(max_depth=3, random_state=42)\n",
      "2021-04-25 16:49:26,170 | INFO     | <ipython-input-12-babc6e1:45   | Модель загружена: PCA(n_components=2)\n"
     ]
    }
   ],
   "source": [
    "# --- ВАШ КОД ТУТ --\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/ping')\n",
    "def ping():\n",
    "    return jsonify({'message': 'pong'})\n",
    "\n",
    "\n",
    "@app.route('/classifier')\n",
    "def classifier():\n",
    "    if not all(param in request.args for param in ('x1', 'x2', 'x3')):\n",
    "        return jsonify({'error': 'query parameters x1, x2, x3 required'})\n",
    "\n",
    "    try:\n",
    "        x1 = float(request.args['x1'])\n",
    "        x2 = float(request.args['x2'])\n",
    "        x3 = float(request.args['x3'])\n",
    "    except (TypeError, ValueError):\n",
    "        logging.error('bad request format')\n",
    "        return jsonify({'error': 'all of x1, x2, x3 query parameters must be float numbers'})\n",
    "\n",
    "    try:\n",
    "        used_features = transformer.transform(np.array([[x1, x2, x3]]))\n",
    "        predicted_class = int(classifier_model.predict(used_features)[0])\n",
    "\n",
    "        response = {'x1': x1, 'x2': x2, 'x3': x3, 'predicted_class': predicted_class}\n",
    "\n",
    "        return jsonify(response)\n",
    "    except Exception as err:\n",
    "        logging.exception(f\"can't predict class for parameters [{x1}, {x2}, {x3}]\")\n",
    "        return jsonify({'error': f'internal error: {repr(err)}'})\n",
    "\n",
    "\n",
    "with open('./clf.pkl', 'rb') as f:\n",
    "    classifier_model = pickle.load(f)\n",
    "    logging.info('Модель загружена: %s' % classifier_model)\n",
    "\n",
    "with open('./pca_transformer.pkl', 'rb') as f:\n",
    "    transformer = pickle.load(f)\n",
    "    logging.info('Модель загружена: %s' % transformer)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    LOG_FORMAT = '%(asctime)s | %(levelname)-8s | %(filename)-25.25s:%(lineno)-4d | %(message)s'\n",
    "    logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\n",
    "\n",
    "#     Disable app start in jupyter notebook\n",
    "#     app.run(port=5001)\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание: строим KNN\n",
    "\n",
    "В реальной жизни KNN-рекомендатель не стоит делать на основе `sklearn.neighbors.NearestNeighbors` - есть готовые реализации, заточенные специально для построения рекомендательных систем. Хорошим примером такой реализации является [пакет implictit](). В рамках домашней работы предлагается разобраться с реализацией KNN-рекомендателя из этой библиотеки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почитайте документацию по модулю `implicit.nearest_neighbours.CosineRecommender`. Обучите KNN-рекомендатель и воспользуйтесь методом `recommend` для построения рекомендаций\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество просмотров 489565\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>view_duration</th>\n",
       "      <th>view_ts</th>\n",
       "      <th>dt</th>\n",
       "      <th>platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4649</td>\n",
       "      <td>52867</td>\n",
       "      <td>735</td>\n",
       "      <td>2019-03-18 20:40:57+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>48800</td>\n",
       "      <td>361</td>\n",
       "      <td>2019-03-18 11:48:27+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5380</td>\n",
       "      <td>47146</td>\n",
       "      <td>268</td>\n",
       "      <td>2019-02-17 13:06:33+03:00</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
       "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
       "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
       "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
       "\n",
       "  platform  \n",
       "0       LG  \n",
       "1       LG  \n",
       "2       LG  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "content_views = pd.read_csv(\n",
    "    'recsys_data/content_views.zip', delimiter=',', header=0, compression='zip',\n",
    "    names = ['user_id', 'content_id', 'view_duration', 'view_ts', 'dt', 'platform'],\n",
    "    dtype = {'user_id': np.uint32, 'content_id': np.uint16, 'view_duration': np.uint16},\n",
    "    parse_dates = [3, 4]\n",
    ")\n",
    "\n",
    "\n",
    "print('Количество просмотров %s' % content_views.user_id.count())\n",
    "\n",
    "content_views.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество доступного контента 126182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>release_date</th>\n",
       "      <th>kinopoisk_rating</th>\n",
       "      <th>compilation_id</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1974</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-15</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2148</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-21</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2184</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-22</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_id  origin_country release_date  kinopoisk_rating  compilation_id  \\\n",
       "0        1974            87.0   2009-12-15              7.27             153   \n",
       "1        2148            87.0   2009-12-21              7.27             153   \n",
       "2        2184            87.0   2009-12-22              7.27             153   \n",
       "\n",
       "       genre  \n",
       "0  Для детей  \n",
       "1  Для детей  \n",
       "2  Для детей  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_description = pd.read_csv(\n",
    "    'recsys_data/content_description.zip', delimiter=',', header=0, compression='zip',\n",
    "    names = ['content_id', 'origin_country', 'release_date', 'kinopoisk_rating', 'compilation_id', 'genre'],\n",
    "    dtype = {'content_id': np.uint16},\n",
    "    parse_dates = [2]\n",
    ")\n",
    "\n",
    "print('Количество доступного контента %s' % content_description.content_id.count())\n",
    "\n",
    "content_description.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>view_duration</th>\n",
       "      <th>view_ts</th>\n",
       "      <th>dt</th>\n",
       "      <th>platform</th>\n",
       "      <th>user_index</th>\n",
       "      <th>item_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4649</td>\n",
       "      <td>52867</td>\n",
       "      <td>735</td>\n",
       "      <td>2019-03-18 20:40:57+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>802</td>\n",
       "      <td>22812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>48800</td>\n",
       "      <td>361</td>\n",
       "      <td>2019-03-18 11:48:27+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>2</td>\n",
       "      <td>20399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5380</td>\n",
       "      <td>47146</td>\n",
       "      <td>268</td>\n",
       "      <td>2019-02-17 13:06:33+03:00</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>LG</td>\n",
       "      <td>911</td>\n",
       "      <td>19628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4498</td>\n",
       "      <td>30191</td>\n",
       "      <td>297</td>\n",
       "      <td>2019-03-18 15:27:18+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>773</td>\n",
       "      <td>13517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4886</td>\n",
       "      <td>39349</td>\n",
       "      <td>302</td>\n",
       "      <td>2019-03-18 12:08:16+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>836</td>\n",
       "      <td>16959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
       "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
       "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
       "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
       "3     4498       30191            297 2019-03-18 15:27:18+03:00 2019-03-18   \n",
       "4     4886       39349            302 2019-03-18 12:08:16+03:00 2019-03-18   \n",
       "\n",
       "  platform  user_index  item_index  \n",
       "0       LG         802       22812  \n",
       "1       LG           2       20399  \n",
       "2       LG         911       19628  \n",
       "3       LG         773       13517  \n",
       "4       LG         836       16959  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# кодируем индексы пользователей\n",
    "user_encoder = LabelEncoder()\n",
    "user_encoder.fit(content_views.user_id)\n",
    "\n",
    "# ереиндексация контента\n",
    "content_views = content_views.assign(\n",
    "    user_index = user_encoder.transform(content_views.user_id)\n",
    ")\n",
    "\n",
    "# кодируем индексы контента\n",
    "item_encoder = LabelEncoder()\n",
    "item_encoder.fit(content_views.content_id)\n",
    "\n",
    "# нова переиндексация\n",
    "content_views = content_views.assign(\n",
    "    item_index = item_encoder.transform(content_views.content_id)\n",
    ")\n",
    "\n",
    "\n",
    "content_views.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.0091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2000x27012 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 259994 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "num_users = content_views.user_index.max() + 1\n",
    "num_items = content_views.item_index.max() + 1\n",
    "num_interactions = content_views.shape[0]\n",
    "\n",
    "user_item = csr_matrix(\n",
    "    (np.ones(num_interactions),(content_views.user_index.values, content_views.item_index.values)),\n",
    "    shape=(num_users, num_items)\n",
    ")\n",
    "print('sparsity: %.4f' % (num_interactions / (num_users * num_items)))\n",
    "\n",
    "user_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки 1600 пользователей, размер валидационной выборки 400 пользователей\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ids, test_ids = train_test_split(\n",
    "    np.arange(start=0, stop=user_item.shape[0], step=1, dtype=np.uint32),\n",
    "    test_size=0.2\n",
    ")\n",
    "print(\n",
    "    \"Размер обучающей выборки %d пользователей, размер валидационной выборки %d пользователей\"\n",
    "    % (train_ids.size, test_ids.size)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine', n_jobs=-1, n_neighbors=20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "\n",
    "# обучаемся только на тренировочной части пользователей\n",
    "model_knn.fit(user_item[train_ids,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColaborativeFilteringKNNRecommender:\n",
    "    def __init__(self, knn_model, user_item_matrix, num_neighbors):\n",
    "        self.knn_model = knn_model\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.top_recs = 50\n",
    "    \n",
    "    def make_recs(self, user_history: csr_matrix, top_recs: int):\n",
    "        neighbors = model_knn.kneighbors(\n",
    "            random_user_history,\n",
    "            self.num_neighbors,\n",
    "            return_distance=False\n",
    "        )[0]\n",
    "        full_recs = user_item[neighbors,:].max(axis=0)\n",
    "        # рекомендации - это то, что насмотрели ближайшие соседи\n",
    "        user_history_ids = user_history.nonzero()[1]\n",
    "        # последовательность id того контента, который смотрели ближайшие соседи\n",
    "        full_recs_ids = full_recs.nonzero()[1][:self.top_recs]\n",
    "        # исключаем из рекомендаций то, что уже было у упользователя в историии\n",
    "        success_recs = np.array([i for i in full_recs_ids if i in user_history_ids])\n",
    "        print(\"Число успешных рекомендаций %d из %d\" % (success_recs.size, top_recs))\n",
    "        \n",
    "        return np.array([i for i in full_recs_ids if i not in user_history_ids])[:10]\n",
    "\n",
    "\n",
    "# объект рекомендателя\n",
    "recommender = ColaborativeFilteringKNNRecommender(\n",
    "    knn_model=model_knn,\n",
    "    user_item_matrix=user_item,\n",
    "    num_neighbors=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число успешных рекомендаций 4 из 10\n",
      "user_index 786, history: [ 0  1  2  5  6  7  8 80 92 94]\n",
      "recommendations: [  9  76 251 252 301 468 469 470 471 472]\n"
     ]
    }
   ],
   "source": [
    "# пример рекомендаций для случайного пользователя\n",
    "random_user_index = 786\n",
    "random_user_history = user_item.getrow(random_user_index).reshape(1, -1)\n",
    "\n",
    "recs = recommender.make_recs(random_user_history, top_recs=10)\n",
    "print('user_index %d, history: %s' % (random_user_index, random_user_history.nonzero()[1][:10]))\n",
    "print('recommendations: %s' % recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a107d68a72f43bdbe5a49569c39d6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(1510, 1.2214190707117298),\n",
       " (141, 1.0),\n",
       " (25, 1.0),\n",
       " (1487, 1.0),\n",
       " (981, 1.0),\n",
       " (1481, 1.0),\n",
       " (289, 1.0),\n",
       " (26, 0.9999999999999702),\n",
       " (1433, 0.9802296092526569),\n",
       " (1264, 0.9639458273010122)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "from implicit.nearest_neighbours import CosineRecommender\n",
    "\n",
    "cosine_recommender = CosineRecommender(K=50, num_threads=0)\n",
    "cosine_recommender.fit(user_item[train_ids,:])\n",
    "\n",
    "cosine_recommender.recommend(random_user_index, user_item[train_ids,:])\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание: Item to Item\n",
    "\n",
    "Решите задачу c2c рекомендаций - вызовите метод `similar_items` для  *item_id=1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1.0),\n",
       " (693, 1.0),\n",
       " (1489, 0.023044900641260895),\n",
       " (704, 0.022599230735278437),\n",
       " (581, 0.019984019174435787),\n",
       " (136, 0.015021044203152742),\n",
       " (230, 0.0024420333880701473)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "cosine_recommender.similar_items(1)\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: обучаем Implicit\n",
    "\n",
    "Почитайте документацию по модулю implicit.als.AlternatingLeastSquares. Обучите ALS-рекомендатель и воспользуйтесь методом recommend для построения рекомендаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-21 17:59:21,727 | WARNING  | utils.py                 :26   | OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f31be8694a544c885406a55e2936bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(497, 0.91815084),\n",
       " (57, 0.7808006),\n",
       " (887, 0.21588716),\n",
       " (803, 0.0818508),\n",
       " (1109, 0.07203824),\n",
       " (236, 0.06840785),\n",
       " (499, 0.062426552),\n",
       " (500, 0.058115765),\n",
       " (1563, 0.05491588),\n",
       " (1015, 0.053727902)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "als_recommender = AlternatingLeastSquares()\n",
    "als_recommender.fit(user_item[train_ids,:])\n",
    "\n",
    "als_recommender.recommend(random_user_index, user_item[train_ids,:])\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание на метрики\n",
    "\n",
    "Даны два вектора - истинная история пользователя и объекты, которые считает релеватными ваша модель\n",
    "\n",
    "Вычислите\n",
    "\n",
    "* precision\n",
    "* recall\n",
    "* precision@5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.1, 0.05183403900280742)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "user_interactions = [47315, 30004, 36322,  8942, 30820,  6086,  9126,   332, 16289,\n",
    "       39106, 39335, 48506, 48654,  9234, 29935,  2678, 36202, 22636, 18007, 39328, 15414, 30016, 35601,\n",
    "    58409, 21313,   386, 16303, 4397, 19644, 51887, 21659, 36325, 53030,  7764, 50266, 58734, 53419, 24121,\n",
    "    50806, 36092,  8868, 28037, 36131, 13561, 16298, 27508, 41722, 30189, 46490,  2676, 43328, 781, 48397,\n",
    "    41369, 39324, 36381, 39635, 27710, 47837, 28525, 12024, 56604, 41664, 37387, 48507, 413, 33526, 20059,\n",
    "    49781, 56648, 16283, 50805, 34254, 39325, 59374, 22620,  8865, 27512, 13875, 30011,  7621,\n",
    "    10544, 28076, 29716, 30054, 20490, 29466, 16852, 39363, 34250, 7024, 33541,   263, 21267, 25690, 23020,\n",
    "    41368, 53414,  2681, 30201] \n",
    "\n",
    "user_recs = [\n",
    "    50820, 27781, 36131, 50812, 36092, 12024, 59155, 30042, 15414, 19882, 21659, 27849, 39328, 34240, 2681,\n",
    "    21267, 50126, 58560, 7764, 49781\n",
    "]\n",
    "\n",
    "# --- ВАШ КОД ТУТ ---\n",
    "\n",
    "relevant_documents = set(user_recs)\n",
    "retreived_documents = set(user_interactions)\n",
    "\n",
    "\n",
    "recall =  len(relevant_documents & retreived_documents) / len(retreived_documents)\n",
    "precision =  len(relevant_documents & retreived_documents) / len(relevant_documents) \n",
    "\n",
    "\n",
    "def average_precission_at(relevant: list, retreived: list, at: int) -> float:\n",
    "    \"\"\"Вроде бы правильно понял, но не уверен.\"\"\"\n",
    "    s = 0\n",
    "    _at = at\n",
    "\n",
    "    for item in relevant:\n",
    "        if at == 0:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            nidx = retreived.index(item) + 1\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        _at -= 1\n",
    "        s += 1/nidx\n",
    "    \n",
    "    return (1/at) * s\n",
    "\n",
    "average_precision_at_5 = average_precission_at(user_recs, user_interactions, 5)\n",
    "\n",
    "precision, recall, average_precision_at_5\n",
    "# -------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
